# Accuracy Results

## Baseline Classifiers

### unigrams

<table border="1" class="dataframe">\n  <thead>\n    <tr style="text-align: right;">\n      <th></th>\n      <th>hashingn=10000g=(1, 1))(test)</th>\n      <th>hashingn=10000g=(1, 1))(train)</th>\n      <th>hashingn=5000g=(1, 1))(test)</th>\n      <th>hashingn=5000g=(1, 1))(train)</th>\n      <th>tfidfn=10000g=(1, 1))(test)</th>\n      <th>tfidfn=10000g=(1, 1))(train)</th>\n      <th>tfidfn=5000g=(1, 1))(test)</th>\n      <th>tfidfn=5000g=(1, 1))(train)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Logistic Regression</th>\n      <td>0.86716</td>\n      <td>0.89780</td>\n      <td>0.85856</td>\n      <td>0.88556</td>\n      <td>0.87080</td>\n      <td>0.91692</td>\n      <td>0.85980</td>\n      <td>0.89988</td>\n    </tr>\n    <tr>\n      <th>NaiveBayes-Bernoulli</th>\n      <td>0.77488</td>\n      <td>0.83124</td>\n      <td>0.76876</td>\n      <td>0.80780</td>\n      <td>0.77488</td>\n      <td>0.83124</td>\n      <td>0.76876</td>\n      <td>0.80780</td>\n    </tr>\n    <tr>\n      <th>NaiveBayes-Gaussian</th>\n      <td>0.63204</td>\n      <td>0.81876</td>\n      <td>0.65572</td>\n      <td>0.78904</td>\n      <td>0.63480</td>\n      <td>0.82904</td>\n      <td>0.66440</td>\n      <td>0.79812</td>\n    </tr>\n  </tbody>\n</table>

### bigrams

<table border="1" class="dataframe">\n  <thead>\n    <tr style="text-align: right;">\n      <th></th>\n      <th>hashingn=10000g=(2, 2))(test)</th>\n      <th>hashingn=10000g=(2, 2))(train)</th>\n      <th>hashingn=5000g=(2, 2))(test)</th>\n      <th>hashingn=5000g=(2, 2))(train)</th>\n      <th>tfidfn=10000g=(2, 2))(test)</th>\n      <th>tfidfn=10000g=(2, 2))(train)</th>\n      <th>tfidfn=5000g=(2, 2))(test)</th>\n      <th>tfidfn=5000g=(2, 2))(train)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Logistic Regression</th>\n      <td>0.70008</td>\n      <td>0.85272</td>\n      <td>0.66504</td>\n      <td>0.78180</td>\n      <td>0.69888</td>\n      <td>0.85684</td>\n      <td>0.66324</td>\n      <td>0.78352</td>\n    </tr>\n    <tr>\n      <th>NaiveBayes-Bernoulli</th>\n      <td>0.64120</td>\n      <td>0.74944</td>\n      <td>0.61220</td>\n      <td>0.68540</td>\n      <td>0.64120</td>\n      <td>0.74944</td>\n      <td>0.61220</td>\n      <td>0.68540</td>\n    </tr>\n    <tr>\n      <th>NaiveBayes-Gaussian</th>\n      <td>0.65488</td>\n      <td>0.81248</td>\n      <td>0.64304</td>\n      <td>0.75708</td>\n      <td>0.65500</td>\n      <td>0.81148</td>\n      <td>0.64244</td>\n      <td>0.75656</td>\n    </tr>\n  </tbody>\n</table>


### bigrams and unigrams

<table border="1" class="dataframe">\n  <thead>\n    <tr style="text-align: right;">\n      <th></th>\n      <th>hashingn=10000g=(1, 2))(test)</th>\n      <th>hashingn=10000g=(1, 2))(train)</th>\n      <th>hashingn=5000g=(1, 2))(test)</th>\n      <th>hashingn=5000g=(1, 2))(train)</th>\n      <th>tfidfn=10000g=(1, 2))(test)</th>\n      <th>tfidfn=10000g=(1, 2))(train)</th>\n      <th>tfidfn=5000g=(1, 2))(test)</th>\n      <th>tfidfn=5000g=(1, 2))(train)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Logistic Regression</th>\n      <td>0.85452</td>\n      <td>0.89976</td>\n      <td>0.83492</td>\n      <td>0.87716</td>\n      <td>0.85496</td>\n      <td>0.91344</td>\n      <td>0.83264</td>\n      <td>0.88476</td>\n    </tr>\n    <tr>\n      <th>NaiveBayes-Bernoulli</th>\n      <td>0.74388</td>\n      <td>0.79920</td>\n      <td>0.72188</td>\n      <td>0.75780</td>\n      <td>0.74388</td>\n      <td>0.79920</td>\n      <td>0.72188</td>\n      <td>0.75780</td>\n    </tr>\n    <tr>\n      <th>NaiveBayes-Gaussian</th>\n      <td>0.73452</td>\n      <td>0.86136</td>\n      <td>0.74116</td>\n      <td>0.83032</td>\n      <td>0.73952</td>\n      <td>0.86340</td>\n      <td>0.74568</td>\n      <td>0.83292</td>\n    </tr>\n  </tbody>\n</table>